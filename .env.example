# User Story Automation - Environment Configuration Template

# ========================================
# AI Provider Configuration
# ========================================

# Use Ollama (Free, Local - No API Key Needed)
# Set to 'false' to use OpenAI instead
USE_OLLAMA=true

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2

# ========================================
# OpenAI Configuration (Only needed if USE_OLLAMA=false)
# ========================================

# Uncomment and set your OpenAI API key if using OpenAI
# auth_key=your_openai_api_key_here
# or
# OPENAI_API_KEY=your_openai_api_key_here

# ========================================
# Server Configuration
# ========================================

# Flask server port (default: 5000)
PORT=5000

# ========================================
# Notes
# ========================================
#
# To use Ollama (recommended for free local usage):
# 1. Install Ollama from https://ollama.ai
# 2. Run: ollama pull llama3.2
# 3. Start Ollama: ollama serve
# 4. Keep USE_OLLAMA=true (default)
#
# To use OpenAI instead:
# 1. Set USE_OLLAMA=false
# 2. Uncomment and set auth_key with your OpenAI API key
# 3. Get API key from https://platform.openai.com/api-keys
