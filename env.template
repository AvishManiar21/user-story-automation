# Environment Variables Template
# Copy this file to .env and update with your values

# LLM Provider Selection
# Options: 'ollama' (recommended, free, local), 'openai' (cloud), 'groq' (free, fast)
# Default: ollama - recommended for local development
LLM_PROVIDER=ollama

# Ollama Configuration (only if LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
# Other Ollama models: mistral, qwen2.5, llama3.1, etc.

# OpenAI Configuration (only if LLM_PROVIDER=openai)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here
# Legacy alternative:
# auth_key=your_openai_api_key_here

# Groq Configuration (only if LLM_PROVIDER=groq)
# Get your API key from: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here

# Flask Server Configuration
PORT=5000

